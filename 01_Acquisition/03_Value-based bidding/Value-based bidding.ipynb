{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa5765-659a-4375-8fe4-593666cb934e",
   "metadata": {},
   "source": [
    "# Value-based bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70f79c-ff37-409b-877d-3eade934b400",
   "metadata": {},
   "source": [
    "Value-based bidding is a strategy where advertisers set bids based on the estimated value each ad click brings to their business, aiming to optimize return on investment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967ef05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9218b8f2-1fac-4ea3-9110-78be59e3ebf6",
   "metadata": {},
   "source": [
    "### Best-in-class solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd793f2-db84-4164-8410-526109fb2495",
   "metadata": {},
   "source": [
    "We define value using CLV, the present value of revenue flows:\n",
    "\n",
    "$$\\text{CLV}_i = \\frac{P_i \\times V_i \\times r_i}{1 + \\text{WACC} - r_i}$$\n",
    "\n",
    "- $P_i$ is price per seat\n",
    "- $V_i$ is seat volume\n",
    "- $r_i$ is retention rate\n",
    "- $WACC$ is the weighted-average cost of capital\n",
    "\n",
    "We need to predict CLV for each customer in the first 24-hours of sign up so we can send that information to advertisers.\n",
    "\n",
    "**Tl;dr:**\n",
    "1. Calculate CLV using known information for current signups.\n",
    "2. Train regression model to predict CLV on unseen signups.\n",
    "\n",
    "**Calculating CLV using known information**\n",
    "- Revenue ($P_i \\cdot V_i$): current MRR\n",
    "- $r_i$: A function of package, with each package estimated using an exponential survival model\n",
    "- $WACC$: 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcb214-5252-44fa-98b7-30560b0bac6f",
   "metadata": {},
   "source": [
    "### Good-enough solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72e782-0d2e-4e1a-b94d-2a416493a515",
   "metadata": {},
   "source": [
    "We still define value as CLV, but we focus on predicting which product the person will convert to (if any).\n",
    "\n",
    "\n",
    "**Tl;dr:**\n",
    "1. Calculate CLV using known information for current signups.\n",
    "2. Train classification model to predict land package on unseen signups.\n",
    "3. Assign the mean CLV of current customers on that package to that package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dca360-3f56-4406-8022-3bbff888399d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df39cd-2731-4ef5-96aa-81a00cecef2e",
   "metadata": {},
   "source": [
    "**$y$ variable**\n",
    "- $CLV_i$\n",
    "- $Product_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee594254-a2e4-4bc6-aa46-2823bb89c7fa",
   "metadata": {},
   "source": [
    "**$x$ variables**\n",
    "- Segment [str]\n",
    "- Education email flag [str]\n",
    "- Company email flag [str]\n",
    "- Industry [str]\n",
    "- Revenue [str]\n",
    "- Employees [str]\n",
    "- City [str]\n",
    "- State [str]\n",
    "- Country [str]\n",
    "- Data residency [str]\n",
    "- GA signup flag [str]\n",
    "- FB signup flag [str]\n",
    "- Feature counts in first 1 day [int]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78cac84-672f-4cbf-9d94-aacef0cff8b4",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5dcc42-d038-4501-96a2-b83bebbc49fb",
   "metadata": {},
   "source": [
    "### Import local XLSX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec7fd30-b48e-4cf6-98ce-62c4a18dbc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patricksweeney/anaconda3/envs/EconML/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workspace_id</th>\n",
       "      <th>product</th>\n",
       "      <th>clv</th>\n",
       "      <th>segment</th>\n",
       "      <th>education_flag</th>\n",
       "      <th>company_email_flag</th>\n",
       "      <th>industry</th>\n",
       "      <th>revenue</th>\n",
       "      <th>employees_range</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transcription_count</th>\n",
       "      <th>highlight_count</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>insight_count</th>\n",
       "      <th>reel_created_count</th>\n",
       "      <th>invite_count</th>\n",
       "      <th>shared_object_note_count</th>\n",
       "      <th>shared_object_insight_count</th>\n",
       "      <th>note_viewed_user_count</th>\n",
       "      <th>tag_viewed_user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00095959-e65b-4256-aeba-06464ae106ac</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Diversified Consumer Services</td>\n",
       "      <td>$50M-$100M</td>\n",
       "      <td>251-1K</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00786b99-40f5-4703-a772-3026df9827ff</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Software &amp; Services</td>\n",
       "      <td>$10B+</td>\n",
       "      <td>100K+</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ddc9a5-85c6-44d9-9968-c37cdad31fcc</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160b311-e4f8-4bbd-a06f-e2b4c80d40a1</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0172345b-7159-4c99-88d9-3e4fa521f14d</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           workspace_id        product  clv     segment  \\\n",
       "0  00095959-e65b-4256-aeba-06464ae106ac  No conversion  0.0       OTHER   \n",
       "1  00786b99-40f5-4703-a772-3026df9827ff  No conversion  0.0  FREE_EMAIL   \n",
       "2  00ddc9a5-85c6-44d9-9968-c37cdad31fcc  No conversion  0.0  FREE_EMAIL   \n",
       "3  0160b311-e4f8-4bbd-a06f-e2b4c80d40a1  No conversion  0.0  FREE_EMAIL   \n",
       "4  0172345b-7159-4c99-88d9-3e4fa521f14d  No conversion  0.0  FREE_EMAIL   \n",
       "\n",
       "   education_flag company_email_flag                       industry  \\\n",
       "0               0                  0  Diversified Consumer Services   \n",
       "1               0                  1            Software & Services   \n",
       "2               0                  1                        Unknown   \n",
       "3               0                  1                        Unknown   \n",
       "4               0                  1                        Unknown   \n",
       "\n",
       "      revenue employees_range           city  ... transcription_count  \\\n",
       "0  $50M-$100M          251-1K        Utrecht  ...                   4   \n",
       "1       $10B+           100K+  Mountain View  ...                   0   \n",
       "2     Unknown         Unknown        Unknown  ...                   0   \n",
       "3     Unknown         Unknown        Unknown  ...                   0   \n",
       "4     Unknown         Unknown        Unknown  ...                   0   \n",
       "\n",
       "  highlight_count  tag_count  insight_count reel_created_count  invite_count  \\\n",
       "0               0          0              0                  0             0   \n",
       "1               0          0              0                  0             0   \n",
       "2               0          0              0                  0             0   \n",
       "3               0          0              0                  0             0   \n",
       "4               0          0              0                  0             0   \n",
       "\n",
       "   shared_object_note_count  shared_object_insight_count  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   note_viewed_user_count  tag_viewed_user_count  \n",
       "0                       0                      0  \n",
       "1                       0                      0  \n",
       "2                       0                      0  \n",
       "3                       1                      0  \n",
       "4                       0                      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_data():\n",
    "    import pandas as pd\n",
    "    file_path = '/Users/patricksweeney/growth/01_Acquisition/03_Value-based bidding/VBB Train 2.xlsx'\n",
    "    data = pd.read_excel(file_path)\n",
    "    return data\n",
    "\n",
    "data = import_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9806086-69da-4527-87b7-5cb04a007f65",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e6308d-4753-4cbc-91b7-813fdb270c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing values are...\n",
      "workspace_id                   0\n",
      "product                        0\n",
      "clv                            0\n",
      "segment                        0\n",
      "education_flag                 0\n",
      "company_email_flag             0\n",
      "industry                       0\n",
      "revenue                        0\n",
      "employees_range                0\n",
      "city                           0\n",
      "state                          0\n",
      "country_code                   0\n",
      "ga_signup_flag                 0\n",
      "fb_signup_flag                 0\n",
      "residency_region               0\n",
      "project_count                  0\n",
      "transcription_count            0\n",
      "highlight_count                0\n",
      "tag_count                      0\n",
      "insight_count                  0\n",
      "reel_created_count             0\n",
      "invite_count                   0\n",
      "shared_object_note_count       0\n",
      "shared_object_insight_count    0\n",
      "note_viewed_user_count         0\n",
      "tag_viewed_user_count          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def find_missing_values(data):\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"Features with missing values are...\")\n",
    "    print(missing_values)\n",
    "\n",
    "find_missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4d317-0898-44a3-b922-05f7f1371e64",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca1c5a-5c59-4a4c-b8b2-89aa6a30f673",
   "metadata": {},
   "source": [
    "### One hot encode\n",
    "\n",
    "\n",
    "One-hot encoding converts categorical variables into a form that can be provided to machine learning algorithms to improve prediction accuracy. It creates binary columns for each category and avoids the misleading ordinal relationships that numeric encoding might imply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f417cd2-fdc5-4ef8-80ca-95461e93e6bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, encoded_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 31\u001b[0m data \u001b[38;5;241m=\u001b[39m one_hot_encode(data, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkspace_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     32\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mone_hot_encode\u001b[0;34m(data, exclude)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Drop original columns and concatenate encoded data\u001b[39;00m\n\u001b[1;32m     25\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns_to_encode, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, encoded_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/reshape/concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    678\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 680\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    681\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    682\u001b[0m )\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    684\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/internals/concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/internals/concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[0;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[1;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    221\u001b[0m             axes[i],\n\u001b[1;32m    222\u001b[0m             indexers[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[0;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/internals/managers.py:576\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 576\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[1;32m    577\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/EconML/lib/python3.11/site-packages/pandas/core/internals/blocks.py:645\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    643\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 645\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    646\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(data, exclude):\n",
    "    # Ensure that 'data' is a pandas DataFrame\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"Input data must be a pandas DataFrame.\")\n",
    "\n",
    "    # Validate 'exclude' as a list\n",
    "    if not isinstance(exclude, list):\n",
    "        raise TypeError(\"'exclude' must be a list of columns.\")\n",
    "\n",
    "    # Select string and categorical columns to encode, excluding the specified columns\n",
    "    columns_to_encode = data.select_dtypes(include=['object', 'category']).columns\n",
    "    columns_to_encode = [col for col in columns_to_encode if col not in exclude]\n",
    "\n",
    "    # Apply OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "    encoded_data = pd.DataFrame(encoder.fit_transform(data[columns_to_encode]))\n",
    "\n",
    "    # Fix column names after encoding\n",
    "    encoded_data.columns = encoder.get_feature_names_out(columns_to_encode)\n",
    "\n",
    "    # Drop original columns and concatenate encoded data\n",
    "    data = data.drop(columns_to_encode, axis=1)\n",
    "    data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = one_hot_encode(data, ['workspace_id', 'product'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcb42c-3b70-43e3-985c-4931dee4da62",
   "metadata": {},
   "source": [
    "### Best-case performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a448f9-06ba-4f99-bf86-6049d36fbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_case(data, y_variable, exclude, continuous_y=True):\n",
    "    # Importing necessary libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.stats import entropy, differential_entropy\n",
    "    from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "\n",
    "    # Exclude specified variables and separate X and Y\n",
    "    X = data.drop(columns=[y_variable] + exclude)\n",
    "    Y = data[y_variable]\n",
    "\n",
    "    # Calculate the entropy of Y-variable\n",
    "    if continuous_y:\n",
    "        # Use differential_entropy for continuous Y\n",
    "        y_entropy = differential_entropy(Y)\n",
    "        # Calculate mutual information for continuous Y\n",
    "        mi = mutual_info_regression(X, Y)\n",
    "    else:\n",
    "        # Use entropy for discrete Y\n",
    "        value_counts = Y.value_counts()\n",
    "        y_entropy = entropy(value_counts)\n",
    "        # Calculate mutual information for discrete Y\n",
    "        mi = mutual_info_classif(X, Y)\n",
    "\n",
    "    total_mi = np.sum(mi)\n",
    "\n",
    "    # Proportion of uncertainty reduced\n",
    "    proportion_reduced = total_mi / y_entropy if y_entropy > 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Entropy of Y-variable: {y_entropy}\")\n",
    "    print(f\"Total Mutual Information (excluding interaction): {total_mi}\")\n",
    "    print(f\"Proportion of Uncertainty Reduced: {proportion_reduced}\")\n",
    "\n",
    "# Example usage\n",
    "best_case(data, 'product', ['clv', 'workspace_id'], continuous_y=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cab925-6e42-4015-b601-04cae4d6d5ce",
   "metadata": {},
   "source": [
    "### Remove redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a54cf8-523f-4b2e-931f-7efffe1ed3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_regression, mutual_info_classif\n",
    "\n",
    "def scikit_prune_features(data, y_variable, exclude, percentile):\n",
    "    # Ensure that 'exclude' is a list\n",
    "    if not isinstance(exclude, list):\n",
    "        raise TypeError(\"'exclude' must be a list of columns.\")\n",
    "\n",
    "    # Separate the features and the target variable\n",
    "    X = data.drop(columns=[y_variable] + exclude)\n",
    "    y = data[y_variable]\n",
    "\n",
    "    # Determine the score function based on the target variable type\n",
    "    if y.dtype == 'float':\n",
    "        score_func = mutual_info_regression\n",
    "    else:\n",
    "        score_func = mutual_info_classif\n",
    "\n",
    "    # Apply SelectPercentile\n",
    "    selector = SelectPercentile(score_func=score_func, percentile=percentile)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    # Get the selected feature names\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    # Combine selected features with excluded columns and target variable\n",
    "    final_data = pd.concat([data[exclude], data[selected_features], data[[y_variable]]], axis=1)\n",
    "\n",
    "    return final_data\n",
    "\n",
    "# Example usage:\n",
    "data = scikit_prune_features(data, 'product', ['workspace_id', 'clv'], 33)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46af7b-ded3-48eb-8eca-307e73a61901",
   "metadata": {},
   "source": [
    "# Predicting $CLV_i$ in first 24-hours (not being used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a24fc8-79fa-431f-95a5-3b7b0abc8436",
   "metadata": {},
   "source": [
    "Performance here is terrible: 0% $r^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeeeeb3-1b4a-4f49-bc53-4dc25740ae98",
   "metadata": {},
   "source": [
    "### Regression with gradient boosting\n",
    "\n",
    "\n",
    "Gradient Boosting is a machine learning technique that builds models sequentially, with each new model correcting the errors of the previous ones, optimizing for a loss function. This approach combines weak predictive models, typically decision trees, into a stronger ensemble, offering high accuracy in various tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc402999-a04d-4377-be92-e57d5dd01fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_regression(data, y_variable, random_state=42):\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "    # Separate the features and target variable\n",
    "    X = data.drop(columns=[y_variable]).select_dtypes(include=np.number)\n",
    "    y = data[y_variable]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # 1. Train model\n",
    "    model = GradientBoostingRegressor(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 2. Test model\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    cross_val_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "    \n",
    "    # Rounding the scores to two decimal places\n",
    "    rounded_scores = [round(score, 2) for score in cross_val_scores]\n",
    "    print(\"Cross-validation scores (R2):\", rounded_scores)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 3. Performance Metrics\n",
    "    mse = round(mean_squared_error(y_test, y_pred), 2)\n",
    "    r2 = round(r2_score(y_test, y_pred), 2)\n",
    "    mae = round(mean_absolute_error(y_test, y_pred), 2)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "    # 4. Plot Predictions vs Actual with adjusted log10 scale\n",
    "    offset = 1e-6  # Small constant to offset zero or negative values\n",
    "    adjusted_y_test = np.log10(y_test + offset)\n",
    "    adjusted_y_pred = np.log10(y_pred + offset)\n",
    "\n",
    "    plt.scatter(adjusted_y_test, adjusted_y_pred)\n",
    "    plt.xlabel(\"Actual Values (log10 scale)\")\n",
    "    plt.ylabel(\"Predicted Values (log10 scale)\")\n",
    "    plt.title(\"Predicted vs Actual Values (log10 scale)\")\n",
    "    \n",
    "    # Line for perfect predictions\n",
    "    min_val = min(adjusted_y_test.min(), adjusted_y_pred.min())\n",
    "    max_val = max(adjusted_y_test.max(), adjusted_y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # 5. Feature Importance - Updated to show only top 10\n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)[-10:]  # Get the indices of the top 10 features\n",
    "    \n",
    "    plt.barh(X.columns[sorted_idx], feature_importance[sorted_idx])\n",
    "    plt.xlabel(\"Gradient Boosting Feature Importance\")\n",
    "    plt.title(\"Top 10 Features\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = gradient_boosting_regression(data, 'clv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea87b8e-8226-4e89-9dba-2a6e0a575836",
   "metadata": {},
   "source": [
    "# Predicting $Package_i$ in first 24 hours (being used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb585147-e49b-4c5e-8100-8823471ea305",
   "metadata": {},
   "source": [
    "We need to be minimising our false negative rate, even if we have an overly sensitive classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eae6ac-2af5-44dc-8429-57bf9b3b720b",
   "metadata": {},
   "source": [
    "### Optional: Make product a binary conversion event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646c372c-18d5-41e0-8f1b-a6a4370eaa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workspace_id</th>\n",
       "      <th>product</th>\n",
       "      <th>clv</th>\n",
       "      <th>segment</th>\n",
       "      <th>education_flag</th>\n",
       "      <th>company_email_flag</th>\n",
       "      <th>industry</th>\n",
       "      <th>revenue</th>\n",
       "      <th>employees_range</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>transcription_count</th>\n",
       "      <th>highlight_count</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>insight_count</th>\n",
       "      <th>reel_created_count</th>\n",
       "      <th>invite_count</th>\n",
       "      <th>shared_object_note_count</th>\n",
       "      <th>shared_object_insight_count</th>\n",
       "      <th>note_viewed_user_count</th>\n",
       "      <th>tag_viewed_user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00095959-e65b-4256-aeba-06464ae106ac</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Diversified Consumer Services</td>\n",
       "      <td>$50M-$100M</td>\n",
       "      <td>251-1K</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00786b99-40f5-4703-a772-3026df9827ff</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Software &amp; Services</td>\n",
       "      <td>$10B+</td>\n",
       "      <td>100K+</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ddc9a5-85c6-44d9-9968-c37cdad31fcc</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160b311-e4f8-4bbd-a06f-e2b4c80d40a1</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0172345b-7159-4c99-88d9-3e4fa521f14d</td>\n",
       "      <td>No conversion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FREE_EMAIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           workspace_id        product  clv     segment  \\\n",
       "0  00095959-e65b-4256-aeba-06464ae106ac  No conversion  0.0       OTHER   \n",
       "1  00786b99-40f5-4703-a772-3026df9827ff  No conversion  0.0  FREE_EMAIL   \n",
       "2  00ddc9a5-85c6-44d9-9968-c37cdad31fcc  No conversion  0.0  FREE_EMAIL   \n",
       "3  0160b311-e4f8-4bbd-a06f-e2b4c80d40a1  No conversion  0.0  FREE_EMAIL   \n",
       "4  0172345b-7159-4c99-88d9-3e4fa521f14d  No conversion  0.0  FREE_EMAIL   \n",
       "\n",
       "   education_flag company_email_flag                       industry  \\\n",
       "0               0                  0  Diversified Consumer Services   \n",
       "1               0                  1            Software & Services   \n",
       "2               0                  1                        Unknown   \n",
       "3               0                  1                        Unknown   \n",
       "4               0                  1                        Unknown   \n",
       "\n",
       "      revenue employees_range           city  ... transcription_count  \\\n",
       "0  $50M-$100M          251-1K        Utrecht  ...                   4   \n",
       "1       $10B+           100K+  Mountain View  ...                   0   \n",
       "2     Unknown         Unknown        Unknown  ...                   0   \n",
       "3     Unknown         Unknown        Unknown  ...                   0   \n",
       "4     Unknown         Unknown        Unknown  ...                   0   \n",
       "\n",
       "  highlight_count  tag_count  insight_count reel_created_count  invite_count  \\\n",
       "0               0          0              0                  0             0   \n",
       "1               0          0              0                  0             0   \n",
       "2               0          0              0                  0             0   \n",
       "3               0          0              0                  0             0   \n",
       "4               0          0              0                  0             0   \n",
       "\n",
       "   shared_object_note_count  shared_object_insight_count  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   note_viewed_user_count  tag_viewed_user_count  \n",
       "0                       0                      0  \n",
       "1                       0                      0  \n",
       "2                       0                      0  \n",
       "3                       1                      0  \n",
       "4                       0                      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_binary_conversion(data, y_variable):\n",
    "    # Check if y_variable exists in the dataframe\n",
    "    if y_variable not in data.columns:\n",
    "        raise ValueError(f\"{y_variable} is not a column in the provided dataframe.\")\n",
    "\n",
    "    # Convert the y_variable to binary\n",
    "    data[y_variable] = data[y_variable].apply(lambda x: 'No conversion' if x == 'No conversion' else 'Conversion')\n",
    "\n",
    "    return data\n",
    "\n",
    "data = make_binary_conversion(data, 'product')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862bfa1-56c7-4ea9-ae8e-bbc32ec93b6b",
   "metadata": {},
   "source": [
    "### Classification with gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e7a6a4-ad28-45cc-aab7-ed608a5c9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(data, y_variable, exclude):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, cohen_kappa_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    random_state = 2\n",
    "    \n",
    "    # Ensure 'exclude' is a list\n",
    "    if not isinstance(exclude, list):\n",
    "        raise TypeError(\"'exclude' must be a list of columns.\")\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = data.drop(columns=[y_variable] + exclude).select_dtypes(include=np.number)\n",
    "    y = data[y_variable]\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Train model\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test model\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    cross_val_scores = cross_val_score(model, X, y, cv=cv, scoring='f1_macro')\n",
    "    print(\"Cross-validation scores:\", cross_val_scores)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # 4. Classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Compute ROC, AUC, Precision-Recall for each class\n",
    "    classes = np.unique(y)\n",
    "    for i, cls in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve((y_test == cls).astype(int), y_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        precision, recall, _ = precision_recall_curve((y_test == cls).astype(int), y_proba[:, i])\n",
    "        \n",
    "        # ROC Curve\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='Class %s AUC = %0.2f' % (cls, roc_auc))\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC for class %s' % cls)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "        # Precision-Recall Curve\n",
    "        plt.figure()\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve for class %s' % cls)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    # # Compute and plot Lift Chart\n",
    "    # df_lift = pd.DataFrame({'y_test': y_test, 'y_proba': y_proba})\n",
    "    # df_lift = df_lift.sort_values(by='y_proba', ascending=False)\n",
    "    # df_lift['decile'] = pd.qcut(df_lift['y_proba'], 10, labels=False)\n",
    "    # df_lift['num_positive'] = df_lift['y_test'].cumsum()\n",
    "    # df_lift['total'] = df_lift.index + 1\n",
    "    # df_lift['lift'] = df_lift['num_positive'] / df_lift['total']\n",
    "\n",
    "    \n",
    "    # Cross-validation score\n",
    "    print(\"Average cross-validation score:\", np.mean(cross_val_scores))\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    print(\"Cohen's Kappa:\", kappa)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82d62f-ce86-4791-84f8-52355aee472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gradient_boosting(data, 'product', ['clv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9fad1-a567-479f-9460-79077b57bfc7",
   "metadata": {},
   "source": [
    "# Get value-weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb18937-4bb2-4d4e-9bfc-1c2f5de68865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data, model, y_variable, exclude):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Filter data where the target variable equals 0\n",
    "    target_data = data\n",
    "\n",
    "    # Exclude specified variables, separate the features, and retain the index\n",
    "    X_target = target_data.drop(columns=[y_variable] + exclude).select_dtypes(include=np.number)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_target)\n",
    "    probabilities = model.predict_proba(X_target)[:, 1]\n",
    "\n",
    "    # Append predictions and probabilities to the original data\n",
    "    data.loc[target_data.index, 'Prediction'] = predictions\n",
    "    data.loc[target_data.index, 'Probability'] = probabilities\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "predictions = get_predictions(data, model, 'product', ['clv'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d692d-926f-44c2-885c-055d694e8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weightings(data, prediction_column, clv_column):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Calculate the average CLV for each prediction category\n",
    "    average_clvs = data.groupby(prediction_column)[clv_column].mean()\n",
    "\n",
    "    # Create a new column 'weighting' with the average CLV for each prediction\n",
    "    data['weighting'] = data[prediction_column].map(average_clvs)\n",
    "\n",
    "    # Select only the necessary columns\n",
    "    data = data[['workspace_id', prediction_column, 'weighting']]\n",
    "\n",
    "    return data\n",
    "\n",
    "weightings = get_weightings(data, 'Prediction', 'clv')\n",
    "weightings.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504c008-90b8-4df3-abf8-1303dcec7ad4",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae549e0-617a-4706-9ecc-fe7fb9ad5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, filename):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Ensure the filename ends with '.xlsx'\n",
    "    if not filename.endswith('.xlsx'):\n",
    "        filename += '.xlsx'\n",
    "\n",
    "    # Save to Excel\n",
    "    predictions.to_excel(filename, index=False)\n",
    "\n",
    "save_predictions(weightings, 'predictions_vbb.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441cca6-7147-4696-8828-16e02b150862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EconML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
