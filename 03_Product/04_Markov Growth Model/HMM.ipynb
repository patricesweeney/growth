{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growth model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dynamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dynamax\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/dynamax.git\n",
    "    import dynamax\n",
    "\n",
    "from dynamax.hidden_markov_model import PoissonHMM, HMM\n",
    "from dynamax.parameters import ParameterProperties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Jax and Tensorflow Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax import jit, lax, vmap, value_and_grad\n",
    "\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from itertools import count\n",
    "from functools import partial\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rates = [40, 3, 20, 50]\n",
    "true_durations = [10, 20, 5, 35]\n",
    "keys = map(jr.PRNGKey, count())\n",
    "\n",
    "emissions = jnp.concatenate(\n",
    "    [\n",
    "        jr.poisson(key, rate, (num_steps,))\n",
    "        for (key, rate, num_steps) in zip(keys, true_rates, true_durations)\n",
    "    ]\n",
    ").astype(jnp.float32)\n",
    "\n",
    "# PoissonHMM requires are least 1D emissions\n",
    "emissions = emissions[:, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197370 entries, 0 to 197369\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                     Non-Null Count   Dtype         \n",
      "---  ------                                     --------------   -----         \n",
      " 0   transcription_hours_total                  1926 non-null    float64       \n",
      " 1   shared_object_project_count                466 non-null     float64       \n",
      " 2   project_count                              980 non-null     float64       \n",
      " 3   shared_object_project_category_count       466 non-null     float64       \n",
      " 4   converted                                  197370 non-null  int64         \n",
      " 5   page_user_count                            13187 non-null   float64       \n",
      " 6   workspace_created_at                       197370 non-null  datetime64[ns]\n",
      " 7   shared_object_tag_count                    466 non-null     float64       \n",
      " 8   insight_count                              928 non-null     float64       \n",
      " 9   mrr_converted                              5220 non-null    float64       \n",
      " 10  invite_count                               547 non-null     float64       \n",
      " 11  workspace_id                               197370 non-null  object        \n",
      " 12  highlight_count                            2169 non-null    float64       \n",
      " 13  shared_object_note_count                   466 non-null     float64       \n",
      " 14  tag_count                                  1888 non-null    float64       \n",
      " 15  converted_date                             5100 non-null    object        \n",
      " 16  t                                          197370 non-null  int64         \n",
      " 17  shared_object_tag_board_count              466 non-null     float64       \n",
      " 18  shared_object_highlight_count              466 non-null     float64       \n",
      " 19  note_count                                 5641 non-null    float64       \n",
      " 20  page_user_hll                              197370 non-null  object        \n",
      " 21  shared_object_insight_count                466 non-null     float64       \n",
      " 22  date                                       197370 non-null  datetime64[ns]\n",
      " 23  comment_count                              0 non-null       float64       \n",
      " 24  shared_object_workspace_field_group_count  466 non-null     float64       \n",
      " 25  transcription_count                        1926 non-null    float64       \n",
      " 26  reel_created_count                         167 non-null     float64       \n",
      " 27  shared_object_count                        466 non-null     float64       \n",
      " 28  reel_viewed_count                          204 non-null     float64       \n",
      " 29  activity_flag                              197370 non-null  bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(22), int64(2), object(3)\n",
      "memory usage: 43.9+ MB\n"
     ]
    }
   ],
   "source": [
    "def import_data_json():\n",
    "    import pandas as pd\n",
    "    # Specify the path to your JSON file\n",
    "    file_path = '/Users/patricksweeney/growth/03_Product/04_Markov Growth Model/Activation test.json'\n",
    "    # Use pandas to read the JSON file\n",
    "    data = pd.read_json(file_path)\n",
    "    return data\n",
    "\n",
    "# Call the function to import your data\n",
    "data = import_data_json()\n",
    "\n",
    "data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription_hours_total</th>\n",
       "      <th>shared_object_project_count</th>\n",
       "      <th>project_count</th>\n",
       "      <th>shared_object_project_category_count</th>\n",
       "      <th>converted</th>\n",
       "      <th>page_user_count</th>\n",
       "      <th>workspace_created_at</th>\n",
       "      <th>shared_object_tag_count</th>\n",
       "      <th>insight_count</th>\n",
       "      <th>mrr_converted</th>\n",
       "      <th>...</th>\n",
       "      <th>page_user_hll</th>\n",
       "      <th>shared_object_insight_count</th>\n",
       "      <th>date</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>shared_object_workspace_field_group_count</th>\n",
       "      <th>transcription_count</th>\n",
       "      <th>reel_created_count</th>\n",
       "      <th>shared_object_count</th>\n",
       "      <th>reel_viewed_count</th>\n",
       "      <th>activity_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\x128b7fd6b11f8423a8d5ca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transcription_hours_total  shared_object_project_count  project_count  \\\n",
       "0                        0.0                          0.0            0.0   \n",
       "1                        0.0                          0.0            0.0   \n",
       "2                        0.0                          0.0            0.0   \n",
       "3                        0.0                          0.0            0.0   \n",
       "4                        0.0                          0.0            0.0   \n",
       "\n",
       "   shared_object_project_category_count  converted  page_user_count  \\\n",
       "0                                   0.0          0              1.0   \n",
       "1                                   0.0          0              0.0   \n",
       "2                                   0.0          0              0.0   \n",
       "3                                   0.0          0              0.0   \n",
       "4                                   0.0          0              0.0   \n",
       "\n",
       "  workspace_created_at  shared_object_tag_count  insight_count  mrr_converted  \\\n",
       "0           2023-10-12                      0.0            0.0            0.0   \n",
       "1           2023-10-12                      0.0            0.0            0.0   \n",
       "2           2023-10-12                      0.0            0.0            0.0   \n",
       "3           2023-10-12                      0.0            0.0            0.0   \n",
       "4           2023-10-12                      0.0            0.0            0.0   \n",
       "\n",
       "   ...             page_user_hll shared_object_insight_count       date  \\\n",
       "0  ...  \\x128b7fd6b11f8423a8d5ca                         0.0 2023-10-12   \n",
       "1  ...                  \\x118b7f                         0.0 2023-10-13   \n",
       "2  ...                  \\x118b7f                         0.0 2023-10-14   \n",
       "3  ...                  \\x118b7f                         0.0 2023-10-15   \n",
       "4  ...                  \\x118b7f                         0.0 2023-10-16   \n",
       "\n",
       "   comment_count  shared_object_workspace_field_group_count  \\\n",
       "0            0.0                                        0.0   \n",
       "1            0.0                                        0.0   \n",
       "2            0.0                                        0.0   \n",
       "3            0.0                                        0.0   \n",
       "4            0.0                                        0.0   \n",
       "\n",
       "  transcription_count  reel_created_count  shared_object_count  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                 0.0                 0.0                  0.0   \n",
       "2                 0.0                 0.0                  0.0   \n",
       "3                 0.0                 0.0                  0.0   \n",
       "4                 0.0                 0.0                  0.0   \n",
       "\n",
       "   reel_viewed_count  activity_flag  \n",
       "0                0.0           True  \n",
       "1                0.0          False  \n",
       "2                0.0          False  \n",
       "3                0.0          False  \n",
       "4                0.0          False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def replace_nans(data, exempt=['converted_at', 'converted']):\n",
    "    columns_to_fill = [col for col in data.columns if col not in exempt]\n",
    "    data[columns_to_fill] = data[columns_to_fill].fillna(0)\n",
    "    return data\n",
    "\n",
    "data = replace_nans(data)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of observations per workspace_id: 30.0\n",
      "Standard deviation of observations per workspace_id: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>transcription_hours_total</th>\n",
       "      <th>shared_object_project_count</th>\n",
       "      <th>project_count</th>\n",
       "      <th>shared_object_project_category_count</th>\n",
       "      <th>converted</th>\n",
       "      <th>page_user_count</th>\n",
       "      <th>workspace_created_at</th>\n",
       "      <th>shared_object_tag_count</th>\n",
       "      <th>insight_count</th>\n",
       "      <th>...</th>\n",
       "      <th>note_count</th>\n",
       "      <th>page_user_hll</th>\n",
       "      <th>shared_object_insight_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>shared_object_workspace_field_group_count</th>\n",
       "      <th>transcription_count</th>\n",
       "      <th>reel_created_count</th>\n",
       "      <th>shared_object_count</th>\n",
       "      <th>reel_viewed_count</th>\n",
       "      <th>activity_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\x128b7fc4ef88c343d5402f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\x118b7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  transcription_hours_total  shared_object_project_count  \\\n",
       "0 2023-10-10                        0.0                          0.0   \n",
       "1 2023-10-11                        0.0                          0.0   \n",
       "2 2023-10-12                        0.0                          0.0   \n",
       "3 2023-10-13                        0.0                          0.0   \n",
       "4 2023-10-14                        0.0                          0.0   \n",
       "\n",
       "   project_count  shared_object_project_category_count  converted  \\\n",
       "0            0.0                                   0.0          0   \n",
       "1            0.0                                   0.0          0   \n",
       "2            0.0                                   0.0          0   \n",
       "3            0.0                                   0.0          0   \n",
       "4            0.0                                   0.0          0   \n",
       "\n",
       "   page_user_count workspace_created_at  shared_object_tag_count  \\\n",
       "0              1.0           2023-10-10                      0.0   \n",
       "1              0.0           2023-10-10                      0.0   \n",
       "2              0.0           2023-10-10                      0.0   \n",
       "3              0.0           2023-10-10                      0.0   \n",
       "4              0.0           2023-10-10                      0.0   \n",
       "\n",
       "   insight_count  ...  note_count             page_user_hll  \\\n",
       "0            0.0  ...         1.0  \\x128b7fc4ef88c343d5402f   \n",
       "1            0.0  ...         0.0                  \\x118b7f   \n",
       "2            0.0  ...         0.0                  \\x118b7f   \n",
       "3            0.0  ...         0.0                  \\x118b7f   \n",
       "4            0.0  ...         0.0                  \\x118b7f   \n",
       "\n",
       "  shared_object_insight_count  comment_count  \\\n",
       "0                         0.0            0.0   \n",
       "1                         0.0            0.0   \n",
       "2                         0.0            0.0   \n",
       "3                         0.0            0.0   \n",
       "4                         0.0            0.0   \n",
       "\n",
       "   shared_object_workspace_field_group_count  transcription_count  \\\n",
       "0                                        0.0                  0.0   \n",
       "1                                        0.0                  0.0   \n",
       "2                                        0.0                  0.0   \n",
       "3                                        0.0                  0.0   \n",
       "4                                        0.0                  0.0   \n",
       "\n",
       "  reel_created_count  shared_object_count  reel_viewed_count  activity_flag  \n",
       "0                0.0                  0.0                0.0           True  \n",
       "1                0.0                  0.0                0.0          False  \n",
       "2                0.0                  0.0                0.0          False  \n",
       "3                0.0                  0.0                0.0          False  \n",
       "4                0.0                  0.0                0.0          False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_dates(data, date_col='date', freq='D', id_col='workspace_id'):\n",
    "    # Check if the date column is present and convert it to datetime\n",
    "    if date_col not in data.columns:\n",
    "        print(\"Available columns in the DataFrame:\", data.columns)\n",
    "        raise KeyError(f\"{date_col} column not found in the DataFrame.\")\n",
    "    \n",
    "    # Convert the date column to datetime format\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    \n",
    "    # Ensure that the date column is not set as the index\n",
    "    if data.index.name == date_col:\n",
    "        data.reset_index(inplace=True)\n",
    "    \n",
    "    # Function to process each group\n",
    "    def process_group(group):\n",
    "        # Ensure group has date column in datetime format\n",
    "        group[date_col] = pd.to_datetime(group[date_col])\n",
    "        \n",
    "        # Generate a complete date range for the group\n",
    "        idx = pd.date_range(start=group[date_col].min(), end=group[date_col].max(), freq=freq)\n",
    "        \n",
    "        # Set date as the index temporarily for reindexing\n",
    "        group.set_index(date_col, inplace=True)\n",
    "        \n",
    "        # Reindex the group to the complete date range, filling non-existent rows with NaNs\n",
    "        group_reindexed = group.reindex(idx)\n",
    "        \n",
    "        # Reset index to bring back the date column\n",
    "        group_reindexed.reset_index(inplace=True)\n",
    "        \n",
    "        # Rename the 'index' column back to date_col\n",
    "        group_reindexed.rename(columns={'index': date_col}, inplace=True)\n",
    "        \n",
    "        # Forward fill non-varying columns, set varying columns to 0\n",
    "        for col in group_reindexed.columns:\n",
    "            if col != id_col and col != date_col:  # Skip the workspace_id and date columns for processing\n",
    "                if len(group_reindexed[col].dropna().unique()) == 1:  # Non-varying column\n",
    "                    group_reindexed[col] = group_reindexed[col].ffill().bfill()\n",
    "                else:  # Varying column\n",
    "                    group_reindexed[col] = group_reindexed[col].fillna(0)\n",
    "        \n",
    "        return group_reindexed\n",
    "\n",
    "    # Apply processing to each group and combine the results\n",
    "    filled_data = data.groupby(id_col, group_keys=False).apply(process_group)\n",
    "    \n",
    "    # Calculate and print the mean and standard deviation of observations per workspace_id\n",
    "    observation_counts = filled_data.groupby(id_col).size()\n",
    "    mean_observations = observation_counts.mean()\n",
    "    std_observations = observation_counts.std()\n",
    "    \n",
    "    print(f\"Mean number of observations per {id_col}: {mean_observations}\")\n",
    "    print(f\"Standard deviation of observations per {id_col}: {std_observations}\")\n",
    "\n",
    "    return filled_data\n",
    "\n",
    "# Example usage:\n",
    "data = fill_dates(data, 'date', 'D', 'workspace_id')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Fixed K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the HMM class with Baum-Welch algorithm for parameter learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonconjugatePoissonHMM(PoissonHMM):\n",
    "    \"\"\"A Poisson HMM with a nonconjugate prior.    \n",
    "    \"\"\"\n",
    "    def __init__(self, num_states, emission_dim, \n",
    "                 emission_prior_loc=0.0,\n",
    "                 emission_prior_scale=1.0):\n",
    "        HMM.__init__(self,\n",
    "            num_states)\n",
    "        self.emission_dim = emission_dim\n",
    "        self.emission_prior_loc = emission_prior_loc\n",
    "        self.emission_prior_scale = emission_prior_scale\n",
    "        \n",
    "    def initialize(self, key, method=\"prior\", initial_probs=None, transition_matrix=None, rates=None):\n",
    "        key1, key2 = jr.split(key)\n",
    "        params, props = HMM.initialize(self, key=key1, \n",
    "                                               method=method, \n",
    "                                               initial_probs=initial_probs, \n",
    "                                               transition_matrix=transition_matrix)\n",
    "        \n",
    "        if rates is None:\n",
    "            prior = tfd.LogNormal(self.emission_prior_loc, self.emission_prior_scale)\n",
    "            rates = prior.sample(seed=key2, sample_shape=(self.num_states, self.emission_dim))\n",
    "            \n",
    "        params['emissions'] = dict(rates=rates)\n",
    "        props['emissions'] = dict(rates=ParameterProperties(constrainer=tfb.Softplus()))\n",
    "        return params, props\n",
    "        \n",
    "    def log_prior(self, params):\n",
    "        return tfd.LogNormal(self.emission_prior_loc, self.emission_prior_scale).log_prob(\n",
    "            params[\"emissions\"][\"rates\"]\n",
    "        ).sum()\n",
    "        \n",
    "    # Default to the standard E and M steps rather than the conjugate updates\n",
    "    # for the PoissonHMM with a gamma prior.\n",
    "    def e_step(self, params, batch_emissions):\n",
    "        return StandardHMM.e_step(self, params, batch_emissions)\n",
    "    \n",
    "    def m_step(self, params, param_props, batch_emissions, batch_posteriors, **batch_covariates):\n",
    "        return StandardHMM.m_step(self, params, param_props, batch_emissions, batch_posteriors, **batch_covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the latent states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state probs:\n",
      "[0.5 0.5]\n",
      "Transition matrix:\n",
      "[[0.95 0.05]\n",
      " [0.05 0.95]]\n"
     ]
    }
   ],
   "source": [
    "def build_latent_state(num_states, max_num_states, daily_change_prob):\n",
    "    # Give probability 0 to states outside of the current model.\n",
    "    def prob(s):\n",
    "        return jnp.where(s < num_states + 1, 1 / num_states, 0.0)\n",
    "\n",
    "    states = jnp.arange(1, max_num_states + 1)\n",
    "    initial_state_probs = vmap(prob)(states)\n",
    "\n",
    "    # Build a transition matrix that transitions only within the current\n",
    "    # `num_states` states.\n",
    "    def transition_prob(i, s):\n",
    "        return jnp.where(\n",
    "            (s <= num_states) & (i <= num_states) & (1 < num_states),\n",
    "            jnp.where(s == i, 1 - daily_change_prob, daily_change_prob / (num_states - 1)),\n",
    "            jnp.where(s == i, 1, 0),\n",
    "        )\n",
    "\n",
    "    transition_probs = vmap(transition_prob, in_axes=(None, 0))(states, states)\n",
    "\n",
    "    return initial_state_probs, transition_probs\n",
    "\n",
    "num_states = 2\n",
    "daily_change_prob = 0.05\n",
    "\n",
    "initial_state_probs, transition_probs = build_latent_state(num_states, num_states, daily_change_prob)\n",
    "print(\"Initial state probs:\\n{}\".format(initial_state_probs))\n",
    "print(\"Transition matrix:\\n{}\".format(transition_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate single workspace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/qcd4flhx2ss47cf1zvclnv540000gn/T/ipykernel_40192/2163039666.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['date'] = pd.to_datetime(filtered_data['date'])\n",
      "/var/folders/_3/qcd4flhx2ss47cf1zvclnv540000gn/T/ipykernel_40192/2163039666.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.sort_values(by='date', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 22)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def isolate_id(data, id='24a55ae6-f255-4b32-b631-c5d414cf0d4d'):\n",
    "    # Filter for the specified id\n",
    "    filtered_data = data[data['workspace_id'] == id]\n",
    "    \n",
    "    # Ensure 'date' column is in datetime format for proper sorting\n",
    "    filtered_data['date'] = pd.to_datetime(filtered_data['date'])\n",
    "    \n",
    "    # Sort by 'date' ascending\n",
    "    filtered_data.sort_values(by='date', inplace=True)\n",
    "    \n",
    "    # Drop all non-numeric columns\n",
    "    numeric_data = filtered_data.select_dtypes(include='number')\n",
    "    \n",
    "    # Drop the 't' column if it exists in numeric_data\n",
    "    if 't' in numeric_data.columns:\n",
    "        numeric_data = numeric_data.drop(columns=['t', 'transcription_hours_total'])\n",
    "    \n",
    "    # # Plot time series of all numeric variables as subplots\n",
    "    # if len(numeric_data.columns) > 0:  # Check if there's any numeric column left\n",
    "    #     fig, axs = plt.subplots(len(numeric_data.columns), 1, figsize=(10, 5*len(numeric_data.columns)), squeeze=False)\n",
    "        \n",
    "    #     for i, col in enumerate(numeric_data.columns):\n",
    "    #         axs[i, 0].plot(filtered_data['date'], numeric_data[col])  # Use 'date' column for x-axis\n",
    "    #         axs[i, 0].set_title(col)\n",
    "    #         axs[i, 0].set_xlabel('Date')\n",
    "    #         axs[i, 0].set_ylabel('Value')\n",
    "        \n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "    # else:\n",
    "    #     print(\"No numeric columns to plot after filtering.\")\n",
    "\n",
    "    return numeric_data\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'data' is your DataFrame and it contains 'workspace_id' and 'date' columns, along with a 't' column\n",
    "numeric_data = isolate_id(data, id='24a55ae6-f255-4b32-b631-c5d414cf0d4d')\n",
    "\n",
    "emissions = jnp.array(numeric_data.values)\n",
    "emissions.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HMM.__init__() missing 3 required positional arguments: 'initial_component', 'transition_component', and 'emission_component'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define variable to represent the unknown log rates.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hmm \u001b[38;5;241m=\u001b[39m NonconjugatePoissonHMM(num_states, \n\u001b[1;32m      3\u001b[0m                              emission_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      4\u001b[0m                              emission_prior_loc\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mlog(emissions\u001b[38;5;241m.\u001b[39mmean()), \n\u001b[1;32m      5\u001b[0m                              emission_prior_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The optimization gets stuck in local optima. This key should find the right states.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m params, param_props \u001b[38;5;241m=\u001b[39m hmm\u001b[38;5;241m.\u001b[39minitialize(jr\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      9\u001b[0m                                      initial_probs\u001b[38;5;241m=\u001b[39minitial_state_probs,\n\u001b[1;32m     10\u001b[0m                                      transition_matrix\u001b[38;5;241m=\u001b[39mtransition_probs)\n",
      "Cell \u001b[0;32mIn[72], line 7\u001b[0m, in \u001b[0;36mNonconjugatePoissonHMM.__init__\u001b[0;34m(self, num_states, emission_dim, emission_prior_loc, emission_prior_scale)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_states, emission_dim, \n\u001b[1;32m      5\u001b[0m              emission_prior_loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      6\u001b[0m              emission_prior_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     HMM\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      8\u001b[0m         num_states)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memission_dim \u001b[38;5;241m=\u001b[39m emission_dim\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memission_prior_loc \u001b[38;5;241m=\u001b[39m emission_prior_loc\n",
      "\u001b[0;31mTypeError\u001b[0m: HMM.__init__() missing 3 required positional arguments: 'initial_component', 'transition_component', and 'emission_component'"
     ]
    }
   ],
   "source": [
    "# Define variable to represent the unknown log rates.\n",
    "hmm = NonconjugatePoissonHMM(num_states, \n",
    "                             emission_dim=1, \n",
    "                             emission_prior_loc=jnp.log(emissions.mean()), \n",
    "                             emission_prior_scale=1.0)\n",
    "\n",
    "# The optimization gets stuck in local optima. This key should find the right states.\n",
    "params, param_props = hmm.initialize(jr.PRNGKey(1),\n",
    "                                     initial_probs=initial_state_probs,\n",
    "                                     transition_matrix=transition_probs)\n",
    "\n",
    "# Freeze the initial distribution and transition matrix\n",
    "param_props[\"initial\"][\"probs\"].trainable = False\n",
    "param_props[\"transitions\"][\"transition_matrix\"].trainable = False\n",
    "\n",
    "# Fit the model with SGD\n",
    "optimizer = optax.adam(1e-1)\n",
    "num_epochs = 1000\n",
    "params, losses = hmm.fit_sgd(params,\n",
    "                     param_props,\n",
    "                     emissions,\n",
    "                     optimizer=optimizer,\n",
    "                     num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel(\"Negative log marginal likelihood\")\n",
    "plt.xlabel(\"iteration\")\n",
    "\n",
    "print(\"Inferred rates: {}\".format(params[\"emissions\"][\"rates\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Variable K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EconML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
